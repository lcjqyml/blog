---
layout:     post
title:      "用ELK搭建监控系统"
subtitle:   ""
date:       2016-10-17
author:     "mubanjiu"
catalog:    true
tags:
 - 技术
 - ELK
 - devops
---

# 用ELK搭建监控系统

> ELK=ElasticSearch + Logstash + Kibana

对于一个软件或互联网公司来说，对计算资源和应用进行监控和告警是非常基础的需求。对于大公司或成熟公司，一个高度定制化的监控系统应该已经存在了很长时间并且非常成熟了。而对于一个初创公司或小公司来说，如何利用现有开源工具快速搭建一套监控系统是我最近在思考的事情。

### 监控系统的用户：
运维，开发，产品

### 监控系统应该可以解决如下的问题：
1. 监控server的各项基础指标，比如memory,cpu,load,network等
2. 监控应用的状态。
3. 搜集应用日志，并进行分析和统计。通过日志分析和统计可得到应用的访问统计，异常统计，业务统计。具有进行大规模日志数据的分析和处理能力。
4. 可制定告警规则。各种监控数据进入系统后，可以根据条件触发告警，实时的将应用异常情况推送到运维、开发或业务人员的IM/SMS上。
5. 可定制的看板。可以将各种实时统计或报表直观的显示出来。


### 可选方案：
1. 日志宝，日志易，Logtail(阿里云)

优势：使用简单

劣势：需上传日志到外部，不灵活，不易扩展，需付费

2. flume-ng + kafka + spark streaming + hbase(es/mysql) + zepplin/自研web展示

优势：灵活，易于扩展，数据分析和处理能力强

劣势：开发难度高，周期长，维护成本高

3. ELK

优势：开源成熟解决方案，使用简单，扩展能力强

劣势：日志分析和处理依靠logstash完成，处理能力较低，无法适应复杂的日志分析场景



结论：初步选择ELK搭建起监控平台，其能够满足当前较为简单的监控和分析需求。未来如果不能适应，再考虑其他方案。



### 搭建ELK测试环境

整个测试环境基于docker来搭建

#### 部署elasticsearch

`docker run -d -v /data/es:/usr/share/elasticsearch/data -p 9200:9200 -p 9300:9300 elasticsearch:5.0`



#### 部署kibana

经测试，kibana官方的5.0的image不能用，无法在es 5.0上创建index。所以选择在centos image上自己手动下载部署kibana 5.0

`docker run -ti -p 5601:5601 centos /bin/bash `

到官方站点下载rpm包并安装：https://www.elastic.co/downloads/kibana


#### 安装X-Pack插件
其为es推出的包含安全，监控，告警等插件的包

Take the Elastic Stack to the next level with Shield (security), Marvel (monitoring), Watcher (alerting), Graph, and reporting. 

在elasticsearch es_home下执行：bin/elasticsearch-plugin install x-pack

重启es

在kibana kibana_home下执行：bin/kibana-plugin install x-pack

重启kibana

访问kibana，默认账号是elastic/changeme 然后新建一个logstash账号给logstash使用

#### 部署logstash

logstash的配置文件位于/opt/logstash/logstash.conf

准备一个access.log用于测试，将该文件也置于/opt/logstash/下

内容为：

    #character at the beginning of a line indicates a comment. Use
    # comments to describe your configuration.
    input {
      file {
        path => /opt/logstash/access.log
      }
    }
    
    # The filter part of this file is commented out to indicate that it is
    # optional.
    filter {
      grok {
        match => { "message" => "%{COMBINEDAPACHELOG}"}
      }
    }
    
    output {
      elasticsearch {
        hosts => [ "192.168.99.100:9200" ]
        user => logstash
        password => logstash
      }
    }

hosts和user/password需设置为真实的值

`docker run -v /opt/logstash:/opt/logstash logstash -f /opt/logstash/logstash.conf `


logstash起来后，可通过kibana页面直接查看access log的情况

![image](/img/elk/kibana-1.png)

### 使用collectd+logstash+es+kibana+timelion来完成对系统的基础监控

对系统的基础状况进行监控：load,cpu,memory,network

collectd 搜集数据通过UDP发送给logstash，logstash使用collectd codec进行解码，生成结构化数据后将数据发送给es；用户使用kibana的timelion插件来查询es中的数据，并进行图表展示。

在监控目标机器上安装collectd

collectd 的配置文件片段：

    LoadPlugin network
    
    <Plugin network>
        <Server "{logstash-host}" "{logstash-port}">
        </Server>
    </Plugin>


logstash的配置文件：

    #character at the beginning of a line indicates a comment. Use
    # comments to describe your configuration.
    input {
        udp {
            port => 25826
            buffer_size => 1452
            workers => 3          # Default is 2
            queue_size => 30000   # Default is 2000
            codec => collectd { }
            type => "collectd"
        }
    }
    
    
    output {
      elasticsearch {
        hosts => [ "192.168.99.100:9200" ]
        user => logstash
        password => logstash
      }
    }

kibana timelion的查询：

load: `.es(collectd_type:load,metric='avg:shortterm').label("1m"), .es(collectd_type:load,metric='avg:midterm').label("5m"), .es(collectd_type:load,metric='avg:longterm').label("15m").title('load')`

cpu: `.es('collectd_type:cpu AND type_instance:user',metric='avg:value').derivative().label("user"),.es('collectd_type:cpu AND type_instance:idle',metric='avg:value').derivative().label("idle").hide(),.es('collectd_type:cpu AND type_instance:system',metric='avg:value').derivative().label("system"),.es('collectd_type:cpu AND type_instance:wait',metric='avg:value').derivative().label("wait").title("cpu")`

network: `.es('collectd_type:if_packets AND plugin_instance:eth0',metric='avg:rx').derivative().label("rx"),.es('collectd_type:if_packets AND plugin_instance:eth0',metric='avg:tx').derivative().label("tx").title(network)`

memory: `.es('collectd_type:memory AND type_instance:used',metric='avg:value').divide(1000000).label("used(MB)"),.es('collectd_type:memory AND type_instance:free',metric='avg:value').divide(1000000).label("free(MB)"),.es('collectd_type:memory AND type_instance:cached',metric='avg:value').divide(1000000).label("cached(MB)"),.es('collectd_type:memory AND type_instance:buffered',metric='avg:value').divide(1000000).label("buffered(MB)").title(memory)`

![image](/img/elk/kibana-2.png)


### 使用logstash-logback-encoder+logstash+es+kibana 来完成对系统日志的汇总和查询

logstash-logback-encoder是一个应用内的logback appender，其将logback的日志（json格式）通过UDP/TCP发送给logstash，logstash将日志存储到es中，kibana 从es中查询日志数据
  
应用内添加如下依赖：

    <dependency>
       <groupId>net.logstash.logback</groupId>
       <artifactId>logstash-logback-encoder</artifactId>
       <version>4.5.1</version>
    </dependency>

在logback.xml中添加将日志发送给logstash的appender

    <appender name="stash" class="net.logstash.logback.appender.LogstashSocketAppender">
      <host>logstashServer</host>
      <!-- port is optional (default value shown) -->
      <port>514</port>
      <customFields>{"appname":"myWebservice"}</customFields>
    </appender>
    <root level="all">
      <appender-ref ref="stash" />
    </root>

logstash的配置片段：

    #character at the beginning of a line indicates a comment. Use
    # comments to describe your configuration.
    input {
        udp {
            port => 25826
            buffer_size => 1452
            workers => 3          # Default is 2
            queue_size => 30000   # Default is 2000
        }
    }
    
    
    output {
      elasticsearch {
        hosts => [ "192.168.99.100:9200" ]
        user => logstash
        password => logstash
      }
    }


![image](/img/elk/kibana-3.png)


总结：ELK平台搭建和使用起来都十分简单，功能强大，能够满足对日志的汇总和简单分析的需求。在生产环境还需要进一步验证，比如对资源的占用情况，对现有应用是否有影响等。
